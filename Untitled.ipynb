{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cefce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import path\n",
    "from copy import copy, deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1733b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'sample_code_submission/'\n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783c4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(model_dir) \n",
    "path.append(problem_dir)\n",
    "path.append(score_dir)\n",
    "path.append(\"./Data_Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ddf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_settings_from_json\n",
    "from data_generator_new import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b74c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_settings = get_settings_from_json('data_jsons/box')\n",
    "for index, settings in enumerate(data_gen_settings):\n",
    "    data_gen = DataGenerator(settings_dict=settings)\n",
    "    data_gen.load_settings()\n",
    "    data_gen.generate_data()\n",
    "    data_gen.save_data(directory=\"sample_data\", file_index=index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4424c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io import load_data, show_data_statistics, write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c3f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'fair_universe_challenge'\n",
    "data_dir = 'sample_data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "594e3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###-------------------------------------###\n",
      "### Data Loading\n",
      "###-------------------------------------###\n",
      "\n",
      "[*] data dir :  sample_data\n",
      "[*] train data dir :  sample_data\\train\\data\n",
      "[*] train labels dir :  sample_data\\train\\labels\n",
      "[*] test data dir :  sample_data\\test\\data\n",
      "[*] test labels dir :  sample_data\\test\\labels\n",
      "[*] settings dir :  sample_data\\settings\n",
      "[+] train data dir found\n",
      "[+] train labels dir found\n",
      "[+] test data dir found\n",
      "[+] test labels dir found\n",
      "[+] settings dir found\n",
      "[+] 6 train and test sets found\n",
      "---------------------------------\n",
      "[+] Train and Test data loaded!\n",
      "---------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sets, test_sets, settings = load_data(data_dir, load_settings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a5eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "X_Trains = [train_set[\"data\"].to_numpy() for train_set in train_sets]\n",
    "Y_Trains = [train_set[\"labels\"] for train_set in train_sets]\n",
    "\n",
    "# Test set\n",
    "X_Tests = [test_set[\"data\"].to_numpy() for test_set in test_sets]\n",
    "Y_Tests = [test_set[\"labels\"] for test_set in test_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f14cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "772ef272",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"dense_6\" (type Dense).\n\nDimensions must be equal, but are 128 and 2 for '{{node dense_6/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_6/MatMul/ReadVariableOp)' with input shapes: [?,128], [2,64].\n\nCall arguments received by layer \"dense_6\" (type Dense):\n  â€¢ inputs=tf.Tensor(shape=(None, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14404\\1579216498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdann_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_Trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m history = model.fit(\n\u001b[0;32m     55\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mX_Trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_Trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mY_Trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_Trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Use 0 as the label for the source domain and 1 for the target domain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14404\\1579216498.py\u001b[0m in \u001b[0;36mdann_model\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mdense_domain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdense_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgradient_reversal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdense_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_target\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mdense_domain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_domain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0moutput_domain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'domain'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_domain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1971\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1972\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1973\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1975\u001b[0m   \u001b[1;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"dense_6\" (type Dense).\n\nDimensions must be equal, but are 128 and 2 for '{{node dense_6/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_6/MatMul/ReadVariableOp)' with input shapes: [?,128], [2,64].\n\nCall arguments received by layer \"dense_6\" (type Dense):\n  â€¢ inputs=tf.Tensor(shape=(None, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Concatenate, Lambda, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dann_model(input_shape):\n",
    "    # Input layers\n",
    "    input_source = Input(shape=input_shape)\n",
    "    input_target = Input(shape=input_shape)\n",
    "\n",
    "    # Shared layers\n",
    "    dense_shared = Dense(64, activation='relu')\n",
    "\n",
    "    # Source domain branch\n",
    "    dense_source = dense_shared(input_source)\n",
    "    dense_source = Dropout(0.5)(dense_source)\n",
    "    output_source = Dense(1, activation='sigmoid', name='source')(dense_source)\n",
    "\n",
    "    # Target domain branch\n",
    "    dense_target = dense_shared(input_target)\n",
    "    dense_target = Dropout(0.5)(dense_target)\n",
    "    output_target = Dense(1, activation='sigmoid', name='target')(dense_target)\n",
    "\n",
    "    # Domain adaptation branch\n",
    "    def gradient_reversal(x, alpha=1.0):\n",
    "        \"\"\"Flips the sign of the gradient during backpropagation\"\"\"\n",
    "        grad = K.gradients(K.mean(x), x)[0]\n",
    "        grad *= alpha\n",
    "        return grad\n",
    "\n",
    "    dense_domain = dense_shared(Lambda(lambda x: gradient_reversal(x))(Concatenate()([dense_source, dense_target])))\n",
    "    dense_domain = Dropout(0.5)(dense_domain)\n",
    "    output_domain = Dense(1, activation='sigmoid', name='domain')(dense_domain)\n",
    "\n",
    "    # Combine into a single model\n",
    "    model = Model(inputs=[input_source, input_target], outputs=[output_source, output_domain])\n",
    "    model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss=['binary_crossentropy', 'binary_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train set\n",
    "X_Trains = [train_set[\"data\"].to_numpy() for train_set in train_sets]\n",
    "Y_Trains = [train_set[\"labels\"] for train_set in train_sets]\n",
    "\n",
    "# Test set\n",
    "X_Tests = [test_set[\"data\"].to_numpy() for test_set in test_sets]\n",
    "Y_Tests = [test_set[\"labels\"] for test_set in test_sets]\n",
    "\n",
    "# Train the model\n",
    "model = dann_model(input_shape=X_Trains[0].shape[1:])\n",
    "history = model.fit(\n",
    "    [X_Trains[0], X_Trains[1]], [Y_Trains[0], [0] * len(Y_Trains[0])],  # Use 0 as the label for the source domain and 1 for the target domain\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_Tests[0], X_Tests[1]], [Y_Tests[0], [1] * len(Y_Tests[0])]),  # Use 1 as the label for the target domain\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad1041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c166f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
