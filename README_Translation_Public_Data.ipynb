{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Fair-Universe Public Data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ihsaan-ullah/fair-universe\n",
    "# %cd fair-universe/starting_kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import path\n",
    "from copy import copy, deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'sample_code_submission/'\n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add directories to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(model_dir) \n",
    "path.append(problem_dir)\n",
    "path.append(score_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 - Import Data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io import load_data, show_data_statistics, write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'fair_universe_challenge'\n",
    "data_dir = 'phase_1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###-------------------------------------###\n",
      "### Data Loading\n",
      "###-------------------------------------###\n",
      "\n",
      "[*] data dir :  phase_1\n",
      "[*] train data dir :  phase_1\\train\\data\n",
      "[*] train labels dir :  phase_1\\train\\labels\n",
      "[*] test data dir :  phase_1\\test\\data\n",
      "[*] test labels dir :  phase_1\\test\\labels\n",
      "[*] settings dir :  phase_1\\settings\n",
      "[+] train data dir found\n",
      "[+] train labels dir found\n",
      "[+] test data dir found\n",
      "[!] test labels dir :  phase_1\\test\\labels  not found\n",
      "[!] settings dir :  phase_1\\settings  not found\n",
      "[+] 16 train and test sets found\n",
      "[-] json file phase_1\\settings\\settings_1.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_2.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_3.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_4.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_5.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_6.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_7.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_8.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_9.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_10.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_11.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_12.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_13.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_14.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_15.json does not exist\n",
      "[-] json file phase_1\\settings\\settings_16.json does not exist\n",
      "---------------------------------\n",
      "[+] Train and Test data loaded!\n",
      "---------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sets, test_sets, settings = load_data(data_dir, load_settings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###-------------------------------------###\n",
      "### Data Statistics Train\n",
      "###-------------------------------------###\n",
      "-------------------\n",
      "Set 1\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 2\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 3\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 4\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 5\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 6\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 7\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 8\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  950\n",
      "[*] Signal points:  50\n",
      "-------------------\n",
      "Set 9\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n",
      "-------------------\n",
      "Set 10\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n",
      "-------------------\n",
      "Set 11\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n",
      "-------------------\n",
      "Set 12\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n",
      "-------------------\n",
      "Set 13\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n",
      "-------------------\n",
      "Set 14\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n",
      "-------------------\n",
      "Set 15\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n",
      "-------------------\n",
      "Set 16\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "[*] Background points:  500\n",
      "[*] Signal points:  500\n"
     ]
    }
   ],
   "source": [
    "show_data_statistics(train_sets, name=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###-------------------------------------###\n",
      "### Data Statistics Test\n",
      "###-------------------------------------###\n",
      "-------------------\n",
      "Set 1\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 2\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 3\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 4\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 5\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 6\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 7\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 8\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 9\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 10\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 11\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 12\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 13\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 14\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 15\n",
      "-------------------\n",
      "[*] Total points:  1000\n",
      "-------------------\n",
      "Set 16\n",
      "-------------------\n",
      "[*] Total points:  1000\n"
     ]
    }
   ],
   "source": [
    "show_data_statistics(test_sets, name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 - Data Augmentation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment_data import get_augmented_data\n",
    "\n",
    "augmented_sets = []\n",
    "for i, _ in enumerate(train_sets):\n",
    "    augmented_set = get_augmented_data(train_sets[i],  test_sets[i])\n",
    "    augmented_sets.append(augmented_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 - Preprocessing\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets_preprocessed, test_sets_preprocessed = [], []\n",
    "for train_set, test_set in zip(train_sets, test_sets):\n",
    "    \n",
    "    train_mean = np.mean(train_set[\"data\"]).values\n",
    "    test_mean = np.mean(test_set[\"data\"]).values\n",
    "\n",
    "    translation = test_mean - train_mean\n",
    "\n",
    "    train_sets_preprocessed.append({\n",
    "        \"data\" : train_set[\"data\"] - translation, \n",
    "        \"labels\" : train_set[\"labels\"] \n",
    "    })\n",
    "\n",
    "    test_sets_preprocessed.append({\n",
    "        \"data\" : test_set[\"data\"] - translation, \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 - Baselines\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we introduce the following baselines:\n",
    "\n",
    "1. Constant model\n",
    "2. NB plain\n",
    "3. NB preprocessing\n",
    "4. LDA plain\n",
    "5. RR plain\n",
    "6. NB data augmentation\n",
    "7. LDA data augmentation\n",
    "8. RR data augmentatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Model and Scoring function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from metric import auc_metric, bac_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Names and settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings = [\n",
    "    {\"display_name\" : \"constant model\", \"model_name\": \"Constant\", \"preprocessing\" : False, \"preprocessing_method\" : \"translation\",  \"data_augmentation\" : False, \"data_augmentation_type\":\"translation\"},\n",
    "    {\"display_name\" : \"NB plain\", \"model_name\": \"NB\", \"preprocessing\" : False, \"preprocessing_method\" : \"translation\", \"data_augmentation\" : False, \"data_augmentation_type\":\"translation\"},\n",
    "    {\"display_name\" : \"NB preprocessing\", \"model_name\": \"NB\", \"preprocessing\" : True, \"preprocessing_method\" : \"translation\", \"data_augmentation\" : False, \"data_augmentation_type\":\"translation\"},\n",
    "    {\"display_name\" : \"LDA plain\", \"model_name\": \"LDA\", \"preprocessing\" : False, \"preprocessing_method\" : \"translation\", \"data_augmentation\" : False, \"data_augmentation_type\":\"translation\"},\n",
    "    {\"display_name\" : \"RR plain\", \"model_name\": \"RR\", \"preprocessing\" : False, \"preprocessing_method\" : \"translation\", \"data_augmentation\" : False, \"data_augmentation_type\":\"translation\"},\n",
    "    {\"display_name\" : \"NB data augmentation\", \"model_name\": \"NB\", \"preprocessing\" : False, \"preprocessing_method\" : \"translation\", \"data_augmentation\" : True, \"data_augmentation_type\":\"translation\"},\n",
    "    {\"display_name\" : \"LDA data augmentation\", \"model_name\": \"LDA\", \"preprocessing\" : False, \"preprocessing_method\" : \"translation\", \"data_augmentation\" : True, \"data_augmentation_type\":\"translation\"},\n",
    "    {\"display_name\" : \"RR data augmentation\", \"model_name\": \"RR\", \"preprocessing\" : False, \"preprocessing_method\" : \"translation\", \"data_augmentation\" : True, \"data_augmentation_type\":\"translation\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Test**  \n",
    "\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Get Predictions\n",
    "- Get Score\n",
    "- Get Metric Scores\n",
    "- Save Predictions\n",
    "- Save Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "### Training Program\n",
      "############################################\n",
      "\n",
      "--------------------------------------------\n",
      "[*] Model : Constant --- Preprocessing: False --- Data Augmentation: False\n",
      "--------------------------------------------\n",
      "\n",
      "\tDataset : 1\n",
      "\t----------------\n",
      "\t[*] Loading Model\n",
      "\t[*] Training Model\n",
      "\t[*] Get Predictions\n",
      "\t[*] Get Scores\n",
      "\t[*] Computing Scores using AUC and BAC\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_Tests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14900\\1832076497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t[*] Computing Scores using AUC and BAC\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mauc_trains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_Trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_hat_score_trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mauc_tests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_Tests\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_hat_score_tests\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mbac_trains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbac_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_Trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_hat_trains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mbac_tests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbac_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_Tests\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_hat_tests\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_Tests' is not defined"
     ]
    }
   ],
   "source": [
    "#---------------------------------\n",
    "# Load Data\n",
    "#---------------------------------\n",
    "# Train set\n",
    "X_Trains = [train_set[\"data\"] for train_set in train_sets]\n",
    "Y_Trains = [train_set[\"labels\"] for train_set in train_sets]\n",
    "\n",
    "# Test set\n",
    "X_Tests = [test_set[\"data\"] for test_set in test_sets]\n",
    "\n",
    "\n",
    "print(\"############################################\")\n",
    "print(\"### Training Program\")\n",
    "print(\"############################################\")\n",
    "\n",
    "#---------------------------------\n",
    "# Loop over model settings\n",
    "#---------------------------------\n",
    "results = []\n",
    "for model_setting in model_settings:\n",
    "\n",
    "    print(\"\\n--------------------------------------------\")\n",
    "    print(\"[*] Model : {} --- Preprocessing: {} --- Data Augmentation: {}\".format(model_setting[\"model_name\"], model_setting[\"preprocessing\"], model_setting[\"data_augmentation\"]))\n",
    "    print(\"--------------------------------------------\")\n",
    "    #---------------------------------\n",
    "    # Predictions Directory\n",
    "    #---------------------------------\n",
    "    # result directory \n",
    "    predictions_dir = os.path.join(result_dir, model_setting[\"model_name\"])\n",
    "    # create result directory if not created\n",
    "    if not os.path.exists(predictions_dir):\n",
    "        os.mkdir(predictions_dir) \n",
    "\n",
    "    #---------------------------------\n",
    "    # Loop over datasets\n",
    "    #---------------------------------\n",
    "    trained_models = []\n",
    "    Y_hat_trains, Y_hat_score_trains = [], []\n",
    "    Y_hat_tests, Y_hat_score_tests = [], []\n",
    "    auc_trains, auc_tests, bac_trains, bac_tests = [],[],[],[]\n",
    "    for index, _ in enumerate(X_Trains):\n",
    "\n",
    "        print(\"\\n\\tDataset : {}\".format(index+1))\n",
    "        print(\"\\t----------------\")\n",
    "\n",
    "        \n",
    "       \n",
    "        # model_name \n",
    "        trained_model_name = model_dir + model_setting[\"model_name\"]\n",
    "\n",
    "        #---------------------------------\n",
    "        # Load Model\n",
    "        #---------------------------------\n",
    "        print(\"\\t[*] Loading Model\")\n",
    "        model = Model(\n",
    "            model_setting[\"model_name\"],\n",
    "            X_Trains[index],\n",
    "            Y_Trains[index],\n",
    "            X_Tests[index],\n",
    "            model_setting[\"preprocessing\"],\n",
    "            model_setting[\"preprocessing_method\"],\n",
    "            model_setting[\"data_augmentation\"],\n",
    "            model_setting[\"data_augmentation_type\"]\n",
    "        )\n",
    "        # Load Trained Model \n",
    "        # model = model.load(trained_model_name) \n",
    "\n",
    "        #---------------------------------\n",
    "        # Train Model\n",
    "        #---------------------------------\n",
    "        # Train model if not trained\n",
    "        print(\"\\t[*] Training Model\")\n",
    "        if not(model.is_trained):\n",
    "            model.fit() \n",
    "\n",
    "        #---------------------------------\n",
    "        # Get Predictions\n",
    "        #---------------------------------\n",
    "        print(\"\\t[*] Get Predictions\")\n",
    "        Y_hat_trains.append(model.predict(X_Trains[index]))\n",
    "        Y_hat_tests.append(model.predict())\n",
    "        \n",
    "        #---------------------------------\n",
    "        # Get Scores/Proba\n",
    "        #---------------------------------\n",
    "        print(\"\\t[*] Get Scores\")\n",
    "        Y_hat_score_trains.append(model.decision_function(X_Trains[index]))\n",
    "        Y_hat_score_tests.append(model.decision_function())\n",
    "\n",
    "        trained_models.append(model)\n",
    "\n",
    "        #---------------------------------\n",
    "        # Get Metric Scores\n",
    "        #---------------------------------\n",
    "        print(\"\\t[*] Computing Scores using AUC and BAC\")\n",
    "        auc_trains.append(round(auc_metric(Y_Trains[index], Y_hat_score_trains[-1]), 2))\n",
    "        auc_tests.append(round(auc_metric(Y_Tests[index], Y_hat_score_tests[-1]), 2))\n",
    "        bac_trains.append(round(bac_metric(Y_Trains[index], Y_hat_trains[-1]), 2))\n",
    "        bac_tests.append(round(bac_metric(Y_Tests[index], Y_hat_tests[-1]), 2))\n",
    "\n",
    "\n",
    "        #---------------------------------\n",
    "        # Save Predictions\n",
    "        #---------------------------------\n",
    "        print(\"\\t[*] Saving Predictions and Scores\")\n",
    "        # prediction file name\n",
    "        prediction_name_train = os.path.join(predictions_dir, \"train_\"+ str(index+1) + \".predictions\")\n",
    "        prediction_name_test = os.path.join(predictions_dir, \"test_\"+ str(index+1) + \".predictions\")\n",
    "\n",
    "        # score file name\n",
    "        score_name_train = os.path.join(predictions_dir, \"train_\"+ str(index+1) + \".scores\")\n",
    "        score_name_test = os.path.join(predictions_dir, \"test_\"+ str(index+1) + \".scores\")\n",
    "        \n",
    "        # save prediction\n",
    "        write(prediction_name_train, Y_hat_score_trains[-1])\n",
    "        write(prediction_name_test, Y_hat_score_tests[-1])\n",
    "\n",
    "        # save score\n",
    "        write(score_name_train, Y_hat_score_trains[-1])\n",
    "        write(score_name_test, Y_hat_score_tests[-1])\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    train_auc_err = round(np.std(auc_trains)/np.sqrt(len(auc_trains)), 2)\n",
    "    test_auc_err = round(np.std(auc_tests)/np.sqrt(len(auc_tests)), 2)\n",
    "    train_bac_err = round(np.std(bac_trains)/np.sqrt(len(bac_trains)), 2)\n",
    "    test_bac_err = round(np.std(bac_tests)/np.sqrt(len(bac_tests)), 2)\n",
    "    train_auc_mean = round(np.mean(auc_trains), 2)\n",
    "    test_auc_mean = round(np.mean(auc_tests), 2)\n",
    "    train_bac_mean = round(np.mean(bac_trains), 2)\n",
    "    test_bac_mean = round(np.mean(bac_tests), 2)\n",
    "\n",
    "    results.append({\n",
    "        \"trained_models\" : trained_models,\n",
    "        \"Y_hat_trains\" : Y_hat_trains,\n",
    "        \"Y_hat_tests\" : Y_hat_tests,\n",
    "        \"Y_hat_score_trains\" : Y_hat_score_trains,\n",
    "        \"Y_hat_score_tests\" : Y_hat_score_tests,\n",
    "        \"auc_trains\" : auc_trains,\n",
    "        \"auc_tests\" : auc_tests,\n",
    "        \"bac_trains\" : bac_trains,\n",
    "        \"bac_tests\" : bac_tests,\n",
    "        \"train_auc_err\" : train_auc_err,\n",
    "        \"test_auc_err\" : test_auc_err,\n",
    "        \"train_bac_err\" : train_bac_err,\n",
    "        \"test_bac_err\" : test_bac_err,\n",
    "        \"train_auc_mean\" : train_auc_mean,\n",
    "        \"test_auc_mean\" : test_auc_mean,\n",
    "        \"train_bac_mean\" : train_bac_mean,\n",
    "        \"test_bac_mean\" : test_bac_mean\n",
    "\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 6 - Scoring\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [\"train_set {}\".format(i) for i in range(1,17)]\n",
    "train_columns.extend([\"avg\", \"std_err\"])\n",
    "test_columns = [\"test_set {}\".format(i) for i in range(1,17)]\n",
    "test_columns.extend([\"avg\", \"std_err\"])\n",
    "\n",
    "\n",
    "train_aucs, test_aucs, train_bacs, test_bacs, indexes = [],[],[],[],[]\n",
    "for model_s, result in zip(model_settings, results):\n",
    "    indexes.append(model_s[\"display_name\"])\n",
    "\n",
    "    train_aucs.append(copy(result[\"auc_trains\"]))\n",
    "    train_aucs[-1].extend([result[\"train_auc_mean\"], result[\"train_auc_err\"]])\n",
    "    test_aucs.append(copy(result[\"auc_tests\"]))\n",
    "    test_aucs[-1].extend([result[\"test_auc_mean\"], result[\"test_auc_err\"]])\n",
    "    train_bacs.append(copy(result[\"bac_trains\"]))\n",
    "    train_bacs[-1].extend([result[\"train_bac_mean\"], result[\"train_bac_err\"]])\n",
    "    test_bacs.append(copy(result[\"bac_tests\"]))\n",
    "    test_bacs[-1].extend([result[\"test_bac_mean\"], result[\"test_bac_err\"]])\n",
    "\n",
    "\n",
    "\n",
    "score_auc_df_train = pd.DataFrame(data=train_aucs, columns=train_columns, index=indexes)\n",
    "score_auc_df_test = pd.DataFrame(data=test_aucs, columns=test_columns, index=indexes)\n",
    "score_bac_df_train = pd.DataFrame(data=train_bacs, columns=train_columns, index=indexes)\n",
    "score_bac_df_test = pd.DataFrame(data=test_bacs, columns=test_columns, index=indexes)\n",
    "\n",
    "\n",
    "score_auc_df_train.to_csv(\"scoring_output/auc_train.csv\")\n",
    "score_auc_df_test.to_csv(\"scoring_output/auc_test.csv\")\n",
    "score_bac_df_train.to_csv(\"scoring_output/bac_train.csv\")\n",
    "score_bac_df_test.to_csv(\"scoring_output/bac_test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_auc_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_auc_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_bac_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_bac_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import visualize_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_score(score_auc_df_train, score_auc_df_test, \"AUC Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_score(score_bac_df_train, score_bac_df_test, \"BAC Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 7 - Submissions\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing \n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission. \n",
    "<br>\n",
    "Keep the sample code simple.<br>\n",
    "\n",
    "<code>python3</code> is required for this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Ingestion Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 $problem_dir/ingestion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Scoring Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 $score_dir/score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "code_submission = 'code_submission_' + the_date + '.zip'\n",
    "# sample_result_submission = '../sample_result_submission_' + the_date + '.zip'\n",
    "zipdir(code_submission, model_dir)\n",
    "# zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit : \" + code_submission + \" to the compeition: https://www.codabench.org/competitions/674/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Code Submission is generated in the directory: `fair-universe/starting_kit/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9e001b0608738f9411416229c98988c04b997dc526fb61c5e4e084e768e3249"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
